{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Container Apps dynamic sessions code interpreter LangChain CSV querying example\n",
    "\n",
    "This notebook demonstrates how to use Azure Container Apps dynamic sessions and LangChain to query a CSV.\n",
    "\n",
    "Start by copying `.env.sample` to `.env` and filling in the values for your Azure Container Apps dynamic sessions code interpreter pool management endpoint and Azure OpenAI endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required packages\n",
    "!python -m pip install python-dotenv langchain langchain-azure-dynamic-sessions azure-identity openai langchainhub langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set up the Azure Chat OpenAI model using managed identity for authentication\n",
    "azure_token = None\n",
    "def token_factory():\n",
    "    global azure_token\n",
    "    if azure_token is None or datetime.datetime.fromtimestamp(azure_token.expires_on, datetime.timezone.utc) < datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(minutes=5):\n",
    "        print(\"Refreshing Azure token...\")\n",
    "        azure_token = DefaultAzureCredential().get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "    return azure_token.token\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    "    openai_api_version=\"2023-09-15-preview\",\n",
    "    streaming=True,\n",
    "    temperature=0,\n",
    "    azure_ad_token_provider=token_factory,\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_azure_dynamic_sessions import SessionsPythonREPLTool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "code_interpreter_tool = SessionsPythonREPLTool(\n",
    "    pool_management_endpoint=os.environ[\"POOL_MANAGEMENT_ENDPOINT\"],\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    code_interpreter_tool,\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, [code_interpreter_tool], prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=[code_interpreter_tool], verbose=True, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Initialize chat history with instructions on how to query data\n",
    "chat_history = []\n",
    "chat_history.append(SystemMessage(content=(\n",
    "    \"To analyze data, execute Python code to read the file and extract the data you need. \"\n",
    "    \"Pandas is available. \"\n",
    "    \"You must start by using `head()` checking the first few rows to see what the data looks like, \"\n",
    "    \"and then write additional queries to complete the analysis.\"\n",
    ")))\n",
    "\n",
    "# Upload the data file\n",
    "remote_file = code_interpreter_tool.upload_file(local_file_path=\"customers.csv\")\n",
    "chat_history.append(SystemMessage(content=f\"The data file `{remote_file.full_path}` has been uploaded.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Refreshing Azure token...\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import pandas as pd\n",
      "\n",
      "data = pd.read_csv('/mnt/data/customers.csv')\n",
      "\n",
      "# Display the first few rows of the data\n",
      "data.head()`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": \"  FirstName    LastName                          Email        Country  \\\\\\n0    Daleen          du  daleen.du.plessis@contoso.com  United States   \\n1       Ben         van        ben.van.zyl@contoso.com  United States   \\n2     Chris  Groenewalt   chris.groenewalt@contoso.com  United States   \\n3    Jannie          du     jannie.du.toit@contoso.com  United States   \\n4    Helena       Botha       helena.botha@contoso.com  United States   \\n\\n         City State  PostCode      StreetAddress Created_date  cid  \\\\\\n0  Washington    DC     20020  12345 Main Street      8/24/12    0   \\n1  Washington    DC     20020  12345 Main Street     10/11/12    1   \\n2  Washington    DC     20020  12345 Main Street     11/30/17    2   \\n3  Louisville    KY     40219  12345 Main Street       6/2/12    3   \\n4  Louisville    KY     40219  12345 Main Street     11/11/14    4   \\n\\n   TotalPurchasesDollars  SatisfactionRating  \\n0                1438.42                4.97  \\n1                8061.64                1.48  \\n2                 624.75                3.33  \\n3                5157.08                2.20  \\n4                 456.32                1.68  \",\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `data[data['State'] == 'AZ']['TotalPurchasesDollars'].mean()`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": 5031.777777777777,\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3mThe average amount purchased by all customers in Arizona is approximately $5031.78.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the average amount purchased by all customers in Arizona?\",\n",
    "        \"chat_history\": chat_history,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import pandas as pd\n",
      "\n",
      "data = pd.read_csv('/mnt/data/customers.csv')\n",
      "state_purchases = data.groupby('State')['Purchases'].sum()\n",
      "state_with_most_purchases = state_purchases.idxmax()\n",
      "state_with_most_purchases`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": null,\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"'Column not found: Purchases'---------------------------------------------------------------------------\\nKeyError                                  Traceback (most recent call last)\\nCell In[2786], line 4\\n      1 import pandas as pd\\n      3 data = pd.read_csv('/mnt/data/customers.csv')\\n----> 4 state_purchases = data.groupby('State')['Purchases'].sum()\\n      5 state_with_most_purchases = state_purchases.idxmax()\\n      6 state_with_most_purchases\\n\\nFile ~/snenv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1416, in DataFrameGroupBy.__getitem__(self, key)\\n   1407 if isinstance(key, tuple) and len(key) > 1:\\n   1408     # if len == 1, then it becomes a SeriesGroupBy and this is actually\\n   1409     # valid syntax, so don't raise warning\\n   1410     warnings.warn(\\n   1411         \\\"Indexing with multiple keys (implicitly converted to a tuple \\\"\\n   1412         \\\"of keys) will be deprecated, use a list instead.\\\",\\n   1413         FutureWarning,\\n   1414         stacklevel=find_stack_level(),\\n   1415     )\\n-> 1416 return super().__getitem__(key)\\n\\nFile ~/snenv/lib/python3.11/site-packages/pandas/core/base.py:248, in SelectionMixin.__getitem__(self, key)\\n    246 else:\\n    247     if key not in self.obj:\\n--> 248         raise KeyError(f\\\"Column not found: {key}\\\")\\n    249     subset = self.obj[key]\\n    250     ndim = subset.ndim\\n\\nKeyError: 'Column not found: Purchases'\\n\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import pandas as pd\n",
      "\n",
      "data = pd.read_csv('/mnt/data/customers.csv')\n",
      "state_purchases = data.groupby('State')['Total Purchases'].sum()\n",
      "state_with_most_purchases = state_purchases.idxmax()\n",
      "state_with_most_purchases`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": null,\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"'Column not found: Total Purchases'---------------------------------------------------------------------------\\nKeyError                                  Traceback (most recent call last)\\nCell In[2787], line 4\\n      1 import pandas as pd\\n      3 data = pd.read_csv('/mnt/data/customers.csv')\\n----> 4 state_purchases = data.groupby('State')['Total Purchases'].sum()\\n      5 state_with_most_purchases = state_purchases.idxmax()\\n      6 state_with_most_purchases\\n\\nFile ~/snenv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1416, in DataFrameGroupBy.__getitem__(self, key)\\n   1407 if isinstance(key, tuple) and len(key) > 1:\\n   1408     # if len == 1, then it becomes a SeriesGroupBy and this is actually\\n   1409     # valid syntax, so don't raise warning\\n   1410     warnings.warn(\\n   1411         \\\"Indexing with multiple keys (implicitly converted to a tuple \\\"\\n   1412         \\\"of keys) will be deprecated, use a list instead.\\\",\\n   1413         FutureWarning,\\n   1414         stacklevel=find_stack_level(),\\n   1415     )\\n-> 1416 return super().__getitem__(key)\\n\\nFile ~/snenv/lib/python3.11/site-packages/pandas/core/base.py:248, in SelectionMixin.__getitem__(self, key)\\n    246 else:\\n    247     if key not in self.obj:\\n--> 248         raise KeyError(f\\\"Column not found: {key}\\\")\\n    249     subset = self.obj[key]\\n    250     ndim = subset.ndim\\n\\nKeyError: 'Column not found: Total Purchases'\\n\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import pandas as pd\n",
      "\n",
      "data = pd.read_csv('/mnt/data/customers.csv')\n",
      "data.head()`\n",
      "responded: It seems that the column names \"Purchases\" and \"Total Purchases\" are not present in the dataset. Let me first check the first few rows of the dataset to understand the column names and data structure.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": \"  FirstName    LastName                          Email        Country  \\\\\\n0    Daleen          du  daleen.du.plessis@contoso.com  United States   \\n1       Ben         van        ben.van.zyl@contoso.com  United States   \\n2     Chris  Groenewalt   chris.groenewalt@contoso.com  United States   \\n3    Jannie          du     jannie.du.toit@contoso.com  United States   \\n4    Helena       Botha       helena.botha@contoso.com  United States   \\n\\n         City State  PostCode      StreetAddress Created_date  cid  \\\\\\n0  Washington    DC     20020  12345 Main Street      8/24/12    0   \\n1  Washington    DC     20020  12345 Main Street     10/11/12    1   \\n2  Washington    DC     20020  12345 Main Street     11/30/17    2   \\n3  Louisville    KY     40219  12345 Main Street       6/2/12    3   \\n4  Louisville    KY     40219  12345 Main Street     11/11/14    4   \\n\\n   TotalPurchasesDollars  SatisfactionRating  \\n0                1438.42                4.97  \\n1                8061.64                1.48  \\n2                 624.75                3.33  \\n3                5157.08                2.20  \\n4                 456.32                1.68  \",\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `state_purchases = data.groupby('State')['TotalPurchasesDollars'].sum()\n",
      "state_with_most_purchases = state_purchases.idxmax()\n",
      "state_with_most_purchases`\n",
      "responded: The dataset contains the following columns:\n",
      "- FirstName\n",
      "- LastName\n",
      "- Email\n",
      "- Country\n",
      "- City\n",
      "- State\n",
      "- PostCode\n",
      "- StreetAddress\n",
      "- Created_date\n",
      "- cid\n",
      "- TotalPurchasesDollars\n",
      "- SatisfactionRating\n",
      "\n",
      "It appears that the column we need to use for the total purchases is \"TotalPurchasesDollars.\" Let me calculate the state with the highest total purchases using this column.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": \"CA\",\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3mThe state with the highest total purchases is California (CA).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the state who has purchased the most stuff?\",\n",
    "        \"chat_history\": chat_history,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import pandas as pd\n",
      "\n",
      "# Read the data from the file\n",
      "data = pd.read_csv('/mnt/data/customers.csv')\n",
      "\n",
      "# Display the first few rows of the data\n",
      "data.head()`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": \"  FirstName    LastName                          Email        Country  \\\\\\n0    Daleen          du  daleen.du.plessis@contoso.com  United States   \\n1       Ben         van        ben.van.zyl@contoso.com  United States   \\n2     Chris  Groenewalt   chris.groenewalt@contoso.com  United States   \\n3    Jannie          du     jannie.du.toit@contoso.com  United States   \\n4    Helena       Botha       helena.botha@contoso.com  United States   \\n\\n         City State  PostCode      StreetAddress Created_date  cid  \\\\\\n0  Washington    DC     20020  12345 Main Street      8/24/12    0   \\n1  Washington    DC     20020  12345 Main Street     10/11/12    1   \\n2  Washington    DC     20020  12345 Main Street     11/30/17    2   \\n3  Louisville    KY     40219  12345 Main Street       6/2/12    3   \\n4  Louisville    KY     40219  12345 Main Street     11/11/14    4   \\n\\n   TotalPurchasesDollars  SatisfactionRating  \\n0                1438.42                4.97  \\n1                8061.64                1.48  \\n2                 624.75                3.33  \\n3                5157.08                2.20  \\n4                 456.32                1.68  \",\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `data.nlargest(5, 'SatisfactionRating')[['FirstName', 'LastName', 'Email', 'SatisfactionRating']]`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"result\": \"    FirstName    LastName                         Email  SatisfactionRating\\n169    Huseyn    Bayramov   huseyn.bayramov@contoso.com                 5.0\\n249     Barys  Bekarevich  barys.bekarevich@contoso.com                 5.0\\n290     Denis      Terzic      denis.terzic@contoso.com                 5.0\\n301     Emina       Begic       emina.begic@contoso.com                 5.0\\n304   Aneliya    Dzhurova  aneliya.dzhurova@contoso.com                 5.0\",\n",
      "  \"stdout\": \"\",\n",
      "  \"stderr\": \"\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3mThe top 5 happiest customers are:\n",
      "\n",
      "1. Huseyn Bayramov - huseyn.bayramov@contoso.com (Satisfaction Rating: 5.0)\n",
      "2. Barys Bekarevich - barys.bekarevich@contoso.com (Satisfaction Rating: 5.0)\n",
      "3. Denis Terzic - denis.terzic@contoso.com (Satisfaction Rating: 5.0)\n",
      "4. Emina Begic - emina.begic@contoso.com (Satisfaction Rating: 5.0)\n",
      "5. Aneliya Dzhurova - aneliya.dzhurova@contoso.com (Satisfaction Rating: 5.0)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Who are the top 5 happiest customers?\",\n",
    "        \"chat_history\": chat_history,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20240528-sessions-csv-7UT2yXui-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
